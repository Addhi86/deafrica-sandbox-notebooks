{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Assessment of WOfS Product Window-based  <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">\n",
    "\n",
    "* **Products used:** \n",
    "[ga_ls8c_wofs_2](https://explorer.digitalearth.africa/ga_ls8c_wofs_2),\n",
    "[ga_ls8c_wofs_2_summary ](https://explorer.digitalearth.africa/ga_ls8c_wofs_2_summary),\n",
    "[usgs_ls8c_level2_2]()\n",
    "\n",
    "Notes:\n",
    "* Landsat 8 collection 2 is confidential at continental level on 26 June 2020.\n",
    "* This notebook should be run in Collection 2 Read Private Workspace should we need to run the Landsat 8 Collection 2 Sample dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "The [Water Observations from Space (WOfS)](https://www.ga.gov.au/scientific-topics/community-safety/flood/wofs/about-wofs) is a derived product from Landsat 8 satellite observations as part of provisional Landsat 8 Collection 2 surface reflectance and shows surface water detected in Africa.\n",
    "Individual water classified images are called Water Observation Feature Layers (WOFLs), and are created in a 1-to-1 relationship with the input satellite data. \n",
    "Hence there is one WOFL for each satellite dataset processed for the occurrence of water.\n",
    "\n",
    "The data in a WOFL is stored as a bit field. This is a binary number, where each digit of the number is independantly set or not based on the presence (1) or absence (0) of a particular attribute (water, cloud, cloud shadow etc). In this way, the single decimal value associated to each pixel can provide information on a variety of features of that pixel. \n",
    "For more information on the structure of WOFLs and how to interact with them, see [Water Observations from Space](../Datasets/Water_Observations_from_Space.ipynb) and [Applying WOfS bitmasking](../Frequently_used_code/Applying_WOfS_bitmasking.ipynb) notebooks. \n",
    "\n",
    "Accuracy assessment for WOfS product in Africa includes generating a confusion error matrix for a WOFL binary classification.\n",
    "The inputs for the estimating the accuracy of WOfS derived product are a binary classification WOFL layer showing water/non-water and a shapefile containing validation points collected by [Collect Earth Online](https://collect.earth/) tool. Validation points are the ground truth or actual data while the extracted value for each location from WOFL is the predicted value. A confusion error matrix containing overall, producer's and user's accuracy is the output of this analysis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "This notebook explains how you can perform accuracy assessment for WOFS derived product using collected ground truth dataset. \n",
    "\n",
    "The notebook demonstrates how to:\n",
    "\n",
    "1. Load validation points for each partner institutions as a list of observations each has a location and month\n",
    "2. Query WOFL data for validation points and capture available WOfS observation available\n",
    "3. Extract statistics for each WOfS observation in each validation point including min, max and mean values for each point (location and month)\n",
    "4. Extract a LUT for each point that contains both validation info and WOfS result for each month \n",
    "5. Generating a confusion error matrix for WOFL classification\n",
    "6. Assessing the accuracy of the classification \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell.\n",
    "\n",
    "After finishing the analysis, you can modify some values in the \"Analysis parameters\" cell and re-run the analysis to load WOFLs for a different location or time period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time \n",
    "import datacube\n",
    "from datacube.utils import masking, geometry \n",
    "import sys\n",
    "import os\n",
    "import dask \n",
    "import rasterio, rasterio.features\n",
    "import xarray\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import geopandas as gpd\n",
    "import subprocess as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy, scipy.ndimage\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #this will suppress the warnings for multiple UTM zones in your AOI \n",
    "\n",
    "sys.path.append(\"../Scripts\")\n",
    "from rasterio.mask import mask\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from shapely.geometry import Point\n",
    "from deafrica_plotting import map_shapefile,display_map, rgb\n",
    "from deafrica_spatialtools import xr_rasterize\n",
    "from deafrica_datahandling import wofs_fuser, mostcommon_crs,load_ard,deepcopy\n",
    "from deafrica_dask import create_local_dask_cluster\n",
    "\n",
    "#for parallelisation \n",
    "from multiprocessing import Pool, Manager\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Activate the datacube database, which provides functionality for loading and displaying stored Earth observation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='WOfS_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load validation points for each partner institutions as a list of observations each has a location and month\n",
    "    * Load the`csv` validation file as pandas dataframe\n",
    "    * Convert the pandas dataframe into ground_truth `shapefile`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the accuracy assesssment of the validation in each AEZ , we need to obtain WOfS surface water observation data that corresponds with the labelled input data locations. \n",
    "\n",
    "The function `collect_training_data` takes our shapefile containing class labels and extracts training data from the datacube over the location specified by the input geometries. The function will also pre-process our training data by stacking the arrays into a useful format and removing an `NaN` (not-a-number) values.\n",
    "\n",
    "\n",
    "> **The following cell can take several minutes to run.** The class labels will be contained in the first column of the output array.  If you set `ncpus > 1`, then this function will be run in parallel across the specified number of processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample WOfS at the ground truth coordinates\n",
    "To load WOFL data, we can first create a re-usable query as below that will define the time period we are interested in, as well as other important parameters that are used to correctly load the data. \n",
    "\n",
    "As WOFLs are created scene-by-scene, and some scenes overlap, it's important when loading data to `group_by` solar day, and ensure that the data between scenes is combined correctly by using the WOfS `fuse_func`.\n",
    "This will merge observations taken on the same day, and ensure that important data isn't lost when overlapping datasets are combined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert the WOFL bit field into a binary array containing True and False values. This allows us to use the WOFL data as a mask that can be applied to other datasets.\n",
    "The `make_mask` function allows us to create a mask using the flag labels (e.g. \"wet\" or \"dry\") rather than the binary numbers we used above. For more details on how to do masking on WOfS, see the [Applying_WOfS_bit_masking](../Frequently_used_code/Applying_WOfS_bitmasking.ipynb) notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Supplementary_data/Validation/Refined/groundtruth_RCMRD.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed_ 0</th>\n",
       "      <th>Unnamed__1</th>\n",
       "      <th>PLOT_ID</th>\n",
       "      <th>LON</th>\n",
       "      <th>LAT</th>\n",
       "      <th>FLAGGED</th>\n",
       "      <th>ANALYSES</th>\n",
       "      <th>SENTINEL2Y</th>\n",
       "      <th>WATER</th>\n",
       "      <th>NO_WATER</th>\n",
       "      <th>BAD_IMAGE</th>\n",
       "      <th>NOT_SURE</th>\n",
       "      <th>CLASS</th>\n",
       "      <th>COMMENT</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>WATERFLAG</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>137387037.0</td>\n",
       "      <td>29.875854</td>\n",
       "      <td>2.178788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1-12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Open water - freshwater</td>\n",
       "      <td>Point is within the river channel</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (2882610.000 277890.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>137387037.0</td>\n",
       "      <td>29.875854</td>\n",
       "      <td>2.178788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1-12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Open water - freshwater</td>\n",
       "      <td>Point is within the river channel</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (2882610.000 277890.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>137387037.0</td>\n",
       "      <td>29.875854</td>\n",
       "      <td>2.178788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1-12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Open water - freshwater</td>\n",
       "      <td>Point is within the river channel</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (2882610.000 277890.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>137387037.0</td>\n",
       "      <td>29.875854</td>\n",
       "      <td>2.178788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1-12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Open water - freshwater</td>\n",
       "      <td>Point is within the river channel</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (2882610.000 277890.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>137387037.0</td>\n",
       "      <td>29.875854</td>\n",
       "      <td>2.178788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>1-12</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Open water - freshwater</td>\n",
       "      <td>Point is within the river channel</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>POINT (2882610.000 277890.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed_ 0  Unnamed__1      PLOT_ID        LON       LAT  FLAGGED  \\\n",
       "0           0           0  137387037.0  29.875854  2.178788      0.0   \n",
       "1           1           0  137387037.0  29.875854  2.178788      0.0   \n",
       "2           2           0  137387037.0  29.875854  2.178788      0.0   \n",
       "3           3           0  137387037.0  29.875854  2.178788      0.0   \n",
       "4           4           0  137387037.0  29.875854  2.178788      0.0   \n",
       "\n",
       "   ANALYSES  SENTINEL2Y WATER NO_WATER BAD_IMAGE NOT_SURE  \\\n",
       "0       1.0        2018  1-12        0        10        0   \n",
       "1       1.0        2018  1-12        0        10        0   \n",
       "2       1.0        2018  1-12        0        10        0   \n",
       "3       1.0        2018  1-12        0        10        0   \n",
       "4       1.0        2018  1-12        0        10        0   \n",
       "\n",
       "                     CLASS                            COMMENT  MONTH  \\\n",
       "0  Open water - freshwater  Point is within the river channel      1   \n",
       "1  Open water - freshwater  Point is within the river channel      2   \n",
       "2  Open water - freshwater  Point is within the river channel      3   \n",
       "3  Open water - freshwater  Point is within the river channel      4   \n",
       "4  Open water - freshwater  Point is within the river channel      5   \n",
       "\n",
       "   WATERFLAG                        geometry  \n",
       "0          1  POINT (2882610.000 277890.000)  \n",
       "1          1  POINT (2882610.000 277890.000)  \n",
       "2          1  POINT (2882610.000 277890.000)  \n",
       "3          1  POINT (2882610.000 277890.000)  \n",
       "4          1  POINT (2882610.000 277890.000)  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = gpd.read_file(path).to_crs('epsg:6933') #reading the table and converting CRS to metric \n",
    "input_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data= input_data.drop(['Unnamed_ 0','Unnamed__1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [(x,y) for x, y in zip(input_data.geometry.x, input_data.geometry.y)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate query object \n",
    "#need to rethink the items x and y for the coordinates \n",
    "query ={'group_by':'solar_day',\n",
    "        'resampling':'nearest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wofs_for_point(index, row, input_data, query, results_wet, results_clear):\n",
    "    dc = datacube.Datacube(app='WOfS_accuracy')\n",
    "    #get the month value for each index\n",
    "    month = input_data.loc[index]['MONTH'] \n",
    "    plot_id = input_data.loc[index]['PLOT_ID']\n",
    "    #set the time for query of the WOfS database according to the month value in the validation table \n",
    "    time = '2018-' + f'{month:02d}' \n",
    "    #this is for having the original query as it is \n",
    "    dc_query = deepcopy(query) \n",
    "    geom = geometry.Geometry(input_data.geometry.values[index].__geo_interface__,  geometry.CRS('EPSG:6933'))\n",
    "    q = {\"geopolygon\":geom}\n",
    "    t = {\"time\":time} \n",
    "    dc_query.update(t)\n",
    "    dc_query.update(q)\n",
    "    wofls = dc.load(product =\"ga_ls8c_wofs_2\",\n",
    "                    y = (input_data.geometry.y[index] - 30.5, input_data.geometry.y[index] + 30.5),\n",
    "                    x =(input_data.geometry.x[index] - 30.5, input_data.geometry.x[index] + 30.5),\n",
    "                    crs = 'EPSG:6933',\n",
    "                    time=time,\n",
    "                    output_crs = 'EPSG:6933',\n",
    "                    resolution=(-30,30))\n",
    "\n",
    "    # # Define a mask for wet and clear pixels \n",
    "    wet_nocloud = {\"water_observed\":True, \"cloud_shadow\":False, \"cloud\":False,\"nodata\":False}\n",
    "\n",
    "    # # Define a mask for dry and clear pixels \n",
    "    dry_nocloud = {\"water_observed\":False, \"cloud_shadow\":False, \"cloud\":False, \"nodata\":False}\n",
    "    wofl_wetnocloud = masking.make_mask(wofls, **wet_nocloud).astype(int) \n",
    "    wofl_drynocloud = masking.make_mask(wofls, **dry_nocloud).astype(int)\n",
    "    clear = (wofl_wetnocloud | wofl_drynocloud).water.all(dim=['x','y']).values\n",
    "    n_clear = clear.sum() #record this and use it to filter out month with no valid data \n",
    "    if n_clear > 0:\n",
    "        wet = wofl_wetnocloud.isel(time=clear).water.max().values  #record this as WOfS has seen water in the 3*3 window\n",
    "    else:\n",
    "        wet = 0 \n",
    "\n",
    "    results_wet.update({str(int(plot_id))+\"_\"+str(month) : int(wet)})\n",
    "    results_clear.update({str(int(plot_id))+\"_\"+str(month) : int(n_clear)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parallel_fun(input_data, query, ncpus):\n",
    "    \n",
    "    manager = mp.Manager()\n",
    "    results_wet = manager.dict()\n",
    "    results_clear = manager.dict()\n",
    "   \n",
    "    # progress bar\n",
    "    pbar = tqdm(total=len(input_data))\n",
    "        \n",
    "    def update(*a):\n",
    "        pbar.update()\n",
    "\n",
    "    with mp.Pool(ncpus) as pool:\n",
    "        for index, row in input_data.iterrows():\n",
    "            pool.apply_async(get_wofs_for_point,\n",
    "                                 [index,\n",
    "                                 row,\n",
    "                                 input_data,\n",
    "                                 query,\n",
    "                                 results_wet,\n",
    "                                 results_clear], callback=update)\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "        pbar.close()\n",
    "        \n",
    "    return results_wet, results_clear\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:50<00:00,  2.52s/it]\n"
     ]
    }
   ],
   "source": [
    "wet, clear= _parallel_fun(input_data[0:20], query, ncpus=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137387037_1 1\n",
      "137387037_2 1\n",
      "137387037_3 1\n",
      "137387037_4 0\n",
      "137387037_5 1\n",
      "137387037_6 1\n",
      "137387037_7 0\n",
      "137387037_8 0\n",
      "137387037_9 0\n",
      "137387037_10 0\n",
      "137387037_11 0\n",
      "137387037_12 0\n",
      "137387038_1 1\n",
      "137387038_2 1\n",
      "137387038_3 1\n",
      "137387038_4 0\n",
      "137387038_5 1\n",
      "137387038_6 1\n",
      "137387038_7 1\n"
     ]
    }
   ],
   "source": [
    "for key,value in wet.items():\n",
    "    print(key,value)\n",
    "#     split key into plot_id and month\n",
    "#     index at PLOT_ID, month, append wet data\n",
    "#     index at PLOT_ID, month, append clear data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the output should be a pandas table like before that you can do the filtering afterwards "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data.to_csv(('../Supplementary_data/Validation/Refined/ground_truth_RCMRD.csv'))\n",
    "input_data.to_csv(('../Supplementary_data/Validation/Refined/validationpoints_w305m.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexNames = (input_data['WATERFLAG'] > 2) & (input_data['CLEAR_OBS'] > 0) & (input_data['FREQUENCY'] > 0) & (input_data['FREQUENCY'] < 1) #that is for or you need to use\n",
    "# indexNames.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#as water flag more than 1 and also clear observation equal to zero \n",
    "indexNames = input_data[(input_data['WATERFLAG'] > 1) | (input_data['CLEAR_OBS'] == 0)].index #that is for or you need to use |\n",
    "#indexNames = input_data[(input_data['WATERFLAG'] == 1) | (input_data['CLASS_WET'] != 0)].index #that is for or you need to use |\n",
    "#indexNames\n",
    "input_data.drop(indexNames, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will count on the number of month for each plotID in the final table \n",
    "count = input_data.groupby(['PLOT_ID'])['MONTH'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the check on the count for each plot id as a csv file \n",
    "count.to_csv('../Supplementary_data/Validation/Refined/final_RCMRD_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.to_csv(('../Supplementary_data/Validation/Refined/ground_truth_RCMRD_final.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Last modified:** January 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DE Africa User Guide's [Tags Index](https://) (placeholder as this does not exist yet)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**:  :index:`WOfS`, :index:`fractional cover`, :index:`deafrica_plotting`, :index:`deafrica_datahandling`, :index:`display_map`, :index:`wofs_fuser`, :index:`WOFL`, :index:`masking`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the groundtruth with a 6933 EPSG as well (conversion) - how to reproject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #generate query object \n",
    "# #need to rethink the items x and y for the coordinates \n",
    "# query ={'resolution':(-30, 30),\n",
    "#         'align':(15,15),\n",
    "#         'group_by':'solar_day',\n",
    "#         'resampling':'nearest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lat = -1.835721214\n",
    "# lon = 30.80427593\n",
    "\n",
    "# wofls = dc.load(product =\"ga_ls8c_wofs_2\", lat = (lat-0.0003,lat+0.0003), lon=(lon-0.0003,lon+0.0003), output_crs = 'EPSG:6933', resolution=(-30,30),time='2018-12',align=(15,15),resampling='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a mask for no clear observations \n",
    "# #no_clear = {\"cloud_shadow\":True, \"cloud\":True, \"nodata\":True}\n",
    "# # Define a mask for wet and clear pixels \n",
    "# wet_nocloud = {\"water_observed\":True, \"cloud_shadow\":False, \"cloud\":False,\"nodata\":False}\n",
    "# # Define a mask for dry and clear pixels \n",
    "# dry_nocloud = {\"water_observed\":False, \"cloud_shadow\":False, \"cloud\":False, \"nodata\":False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wofl_wetnocloud = masking.make_mask(wofls, **wet_nocloud).astype(int) \n",
    "# wofl_drynocloud = masking.make_mask(wofls, **dry_nocloud).astype(int)\n",
    "# clear = (wofl_wetnocloud | wofl_drynocloud).water.all(dim=['x','y']).values\n",
    "# n_clear = clear.sum() #record this and use it to filter out month with no valid data \n",
    "# if n_clear > 0:\n",
    "#     wet = wofl_wetnocloud.isel(time=clear).water.max().values  #record this as WOfS has seen water in the 3*3 window\n",
    "# else:\n",
    "#     wet = 0 \n",
    "# print(n_clear,wet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "9e3fa49adf8c4170abfcd954c2ec045a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "dc642f11c1fb492ca419b0ed6fc4f8c3": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
