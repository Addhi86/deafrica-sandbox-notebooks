{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water detection with Sentinel-1 <img align=\"right\" src=\"../Supplementary_data/DE_Africa_Logo_Stacked_RGB_small.jpg\">\n",
    "\n",
    "* **Products used:** \n",
    "[s1_rtc](https://explorer.digitalearth.africa/products/s1_rtc)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Keywords**: :index:`data used; sentinel-1`,:index:`SAR`, :index:`water`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "Over 40% of the worldâ€™s population lives within 100 km of the coastline.\n",
    "However, coastal environments are constantly changing, with erosion and coastal change presenting a major challenge to valuable coastal infrastructure and important ecological habitats.\n",
    "Updating data on the position of the coastline is essential for coastal managers to be able to identify and minimise the impacts of coastal change and erosion. \n",
    "The coastal regions are also home to many wetlands. Monitoring of water extent helps to understand and protect these dynamic and productive ecosystems.\n",
    "\n",
    "While coastlines and water extents can be mapped using optical data (demonstrated in the [Coastal Erosion notebook](../Real_world_examples/Coastal_erosion.ipynb)), these images can be strongly affected by the weather, especially through the presence of clouds, which obscure the land and water below.\n",
    "This can be a particular problem in cloudy regions or areas where clouds in wet season prevent optical satellites from taking clear images for many months of the year.\n",
    "\n",
    "Radar observations are largely unaffected by cloud cover.\n",
    "The two Sentinel-1 satellites, operated by ESA as part of the Copernicus program, provide all-weather observations every 6 to 12 days over Africa.\n",
    "By developing a process to classify the observed pixels as either water or land, it is possible to identify the shoreline and map the dynamic water extents using radar data.\n",
    "For more information, see the [Sentinel-1](../Datasets/Sentinel_1.ipynb) notebook.\n",
    "\n",
    "## Description\n",
    "\n",
    "In this example, we use data from the Sentinel-1 satellites to build a classifier that can determine whether a pixel is a water or land.\n",
    "Specifically, this notebook uses analysis-ready radar backscatter, which describes the strength of the signal received by the satellite.\n",
    "\n",
    "The notebook contains the following steps:\n",
    "\n",
    "1. Load Sentinel-1 backscatter data for an area of interest and visualize the returned data\n",
    "2. Applying speckle filter and converting the digital numbers to dB values for analysis\n",
    "3. Use histogram analysis to determine the threshold for water classification\n",
    "4. Design a classifier to distinguish land and water\n",
    "5. Apply the classifier to the area of interest and interpret the results\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Import Python packages that are used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import warnings \n",
    "import datacube\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from scipy.ndimage.filters import uniform_filter\n",
    "from scipy.ndimage.measurements import variance\n",
    "\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.plotting import display_map, rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DEA data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app=\"Radar_water_detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "The following cell sets the parameters, which define the area of interest and the length of time to conduct the analysis.\n",
    "The parameters are\n",
    "\n",
    "* `lat`: The central latitude to analyse (e.g. `10.338`).\n",
    "* `lon`: The central longitude to analyse (e.g. `-1.055`).\n",
    "* `buffer`: The number of square degrees to load around the central latitude and longitude. \n",
    "For reasonable loading times, set this as `0.1` or lower.\n",
    "* `time_range`: The date range to analyse (e.g. `('2020') `)\n",
    "\n",
    "**If running the notebook for the first time**, keep the default settings below.\n",
    "This will demonstrate how the analysis works and provide meaningful results.\n",
    "The example covers the coast of Gomoa Fetteh, Ghana.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select location\n",
    "\n",
    "The selected latitude and longitude will be displayed as a red box on the map below the next cell. \n",
    "This map can be used to find coordinates of other places, simply scroll and click on any point on the map to display the latitude and longitude of that location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the area of interest\n",
    "lat = 12.62 \n",
    "lon = -16.29  \n",
    "buffer = 0.05\n",
    "\n",
    "# Compute the bounding box for the study area\n",
    "lat_range = (lat-buffer, lat+buffer)\n",
    "lon_range = (lon-buffer, lon+buffer)\n",
    "\n",
    "#timeframe\n",
    "timerange = ('2020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the selected location\n",
    "The next cell will display the selected area on an interactive map.\n",
    "Feel free to zoom in and out to get a better understanding of the area you'll be analysing.\n",
    "Clicking on any point of the map will reveal the latitude and longitude coordinates of that point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_map(x=lon_range, y=lat_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and view Sentinel-1 data\n",
    "\n",
    "The first step in the analysis is to load Sentinel-1 backscatter data for the specified area of interest. This uses the pre-defined [load_ard](../Frequently_used_code/Using_load_ard.ipynb) utility function. \n",
    "\n",
    "**Please be patient**.\n",
    "The data may take a few minutes to load and progress will be indicated by text output.\n",
    "The load is complete when the cell status goes from `[*]` to `[number]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Sentinel-1 data\n",
    "S1 = load_ard(dc=dc,\n",
    "              products=[\"s1_rtc\"],\n",
    "              measurements=['vv', 'vh'],\n",
    "              y=lat_range,\n",
    "              x=lon_range,\n",
    "              time=timerange,\n",
    "              output_crs = \"EPSG:6933\",\n",
    "              resolution = (-20,20),\n",
    "              group_by=\"solar_day\",\n",
    "              dtype='native'\n",
    "             )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Once the load is complete**, examine the data by printing it in the next cell.\n",
    "The `Dimensions` argument reveals the number of time steps in the data set, as well as the number of pixels in the `x` (longitude) and `y` (latitude) dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(S1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coastal and wetlands are highly dynamic, so cloud-free assessment using radar is valuable to capture change in all seasons. In the next few cells, Sentinel-1 observations in different polarisations are plotted for selected dates. Noting VV backscatter is usually significantly higher than VH. Signals from the two polarizations are dominated by different scattering mechanisms therefore respond differently to surface characeristics. \n",
    "\n",
    "Both polarizations show siginficant surface cover change over time. Open water is characterized by low backscatter due to specular reflection. Water area with standing vegetation leads to high backscatter and will not be mapped using the thresholding method below. This may result in differenct water extent measurement compared to methods using optical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting a few images from the loaded S1 to visualise \n",
    "timesteps = [2,4,6,9,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VH polarisation for specific timeframe \n",
    "S1.vv.isel(time=timesteps).plot(cmap=\"Greys_r\", robust=True, col=\"time\", col_wrap=5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot VH polarisation for specific timeframe \n",
    "S1.vh.isel(time=timesteps).plot(cmap=\"Greys_r\", robust=True, col=\"time\", col_wrap=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backscatter measurements can be combined in visualization to highlight the different polarization signatures. \n",
    "For the RGB visualization below, the ratio between VH and VV is added as a third measurement band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VH/VV is a potentially useful third feature after VV and VH \n",
    "S1['vh/vv'] = S1.vh/S1.vv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median values are used to scale the measurements so they have a similar range for visualization\n",
    "med_s1 = S1[['vv','vh','vh/vv']].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting an RGB image for selected timesteps\n",
    "rgb(S1[['vv', 'vh', 'vh/vv']]/med_s1, bands=['vv',\n",
    "    'vh', 'vh/vv'], index=timesteps, col_wrap=5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Significant changes in color pattern are visible from month to month. \n",
    "Open water and smooth bare surface appear dark blue because all measurements are low. \n",
    "Tree cover appears cyan because of the relatively higher VH signal from volume scattering. \n",
    "Areas in bright red are likely water with standing vegetation.\n",
    "Urban area is shown in bright yellow at the bottom of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply speckle filtering to the clean the data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radar observations appear speckly due to random interference of coherent signals from target scatters. \n",
    "The speckle noise can be reduced by averaging pixel values over an area or over time. \n",
    "However, averaging over a fixed window smoothes out real local spatial variation and leads to reduced spatial resolution.\n",
    "An adaptive approach that takes into account local homogeneity is therefore preferred.\n",
    "\n",
    "Below, we apply the Lee filter, one of the popular adaptive speckle filters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function to apply lee filtering on S1 image \n",
    "def lee_filter(da, size):\n",
    "    \"\"\"\n",
    "    Apply lee filter of specified window size.\n",
    "    Adapted from https://stackoverflow.com/questions/39785970/speckle-lee-filter-in-python\n",
    "\n",
    "    \"\"\"\n",
    "    img = da.values\n",
    "    img_mean = uniform_filter(img, (size, size))\n",
    "    img_sqr_mean = uniform_filter(img**2, (size, size))\n",
    "    img_variance = img_sqr_mean - img_mean**2\n",
    "\n",
    "    overall_variance = variance(img)\n",
    "\n",
    "    img_weights = img_variance / (img_variance + overall_variance)\n",
    "    img_output = img_mean + img_weights * (img - img_mean)\n",
    "    \n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've defined the filter, we can run it on the VV and VH data. You might have noticed that the function takes a size argument. This will change how blurred the image becomes after smoothing. We've picked a default value for this analysis, but you can experiement with this if you're interested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The lee filter above doesn't handle null values\n",
    "# We therefore set null values to 0 before applying the filter\n",
    "valid = xr.ufuncs.isfinite(S1)\n",
    "S1 = S1.where(valid, 0)\n",
    "\n",
    "# Create a new entry in dataset corresponding to filtered VV and VH data\n",
    "S1[\"filtered_vv\"] = S1.vv.groupby(\"time\").apply(lee_filter, size=7)\n",
    "S1[\"filtered_vh\"] = S1.vh.groupby(\"time\").apply(lee_filter, size=7)\n",
    "\n",
    "# Null pixels should remain null\n",
    "S1['filtered_vv'] = S1.filtered_vv.where(valid.vv)\n",
    "S1['filtered_vh'] = S1.filtered_vh.where(valid.vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images appear smoother after speckle filtering\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "S1[\"filtered_vv\"].isel(time=3).plot(ax = ax[0],robust=True)\n",
    "S1[\"filtered_vh\"].isel(time=3).plot(ax = ax[1],robust=True);\n",
    "ax[0].set_title('VV')\n",
    "ax[1].set_title('VH')\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the digital numbers to dB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While Sentinel-1 backscatter is provided as linear intensiy, it is often useful to convert the backscatter to decible (dB) for analysis. \n",
    "Backscatter in dB unit has a more symmetric noise profile and less skewed value distribution for easier statistical evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1['filtered_vv'] = 10 * xr.ufuncs.log10(S1.filtered_vv)\n",
    "S1['filtered_vh'] = 10 * xr.ufuncs.log10(S1.filtered_vh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram analysis for Sentinel-1\n",
    "\n",
    "Backscatter distributions are plotted below as histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 3))\n",
    "S1.filtered_vh.plot.hist(bins=1000, label=\"VH filtered\")\n",
    "S1.filtered_vv.plot.hist(bins=1000, label=\"VV filtered\",alpha=0.5)\n",
    "plt.xlim(-40,-1)\n",
    "plt.legend()\n",
    "plt.xlabel(\"DN values in(dB)\")\n",
    "plt.title(\"Comparison of Lee filtered VH and VV polarisation bands\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build and apply the classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram for VH backscatter shows a bimodal distribution with low values over water and high values over land.\n",
    "The VV histogram has multiple peaks and less obvious seperation between water and land.\n",
    "\n",
    "We therefore build a classifier based on VH backscatter. \n",
    "We choose a threshold to separate land and water: pixels with values below the threshold are water, and pixels with values above the threshold are not water (land).\n",
    "\n",
    "There are several ways to determine the threshold; one is to estimate it by looking at the *VH* histogram.\n",
    "From this, we might guess that $\\text{threshold_vh} = -25$ is a reasonable value and write a function to only return the pixels that are classified as water. The basic steps that the function will perform are:\n",
    "\n",
    "1. Find all pixels that have filtered values lower than the threshold; these are the `water` pixels.\n",
    "2. Return a data set containing the `water` pixels.\n",
    "\n",
    "These steps correspond to the actions taken in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_vh = -25.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualise threshold\n",
    "\n",
    "To check if our chosen threshold reasonably divides the two distributions, we can add the threshold to the histogram plots we made earlier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 3))\n",
    "S1.filtered_vh.plot.hist(bins=1000, label=\"VH filtered\")\n",
    "plt.xlim(-40,-5)\n",
    "ax.axvspan(xmin=-40.0, xmax=threshold_vh, alpha=0.25, color=\"green\", label=\"Water\")\n",
    "ax.axvspan(xmin=threshold_vh,\n",
    "           xmax=-5,\n",
    "           alpha=0.25,\n",
    "           color=\"red\",\n",
    "           label=\"Not Water\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"VH (dB)\")\n",
    "plt.title(\"Effect of the classifier\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def S1_water_classifier(da, threshold=threshold_vh):\n",
    "    water_data_array = da < threshold\n",
    "    return water_data_array.to_dataset(name=\"s1_water\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined the classifier function, we can apply it to the data. After running the classifier, we will able to view the classified data product by running `print(S1.water)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1['water'] = S1_water_classifier(S1.filtered_vh).s1_water"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment with mean\n",
    "\n",
    "We can now view the image with our classification.\n",
    "The classifier returns either `True` or `False` for each pixel.\n",
    "To detect the boundaries of water features, we want to check which pixels are always water and which are always land.\n",
    "Conveniently, Python encodes `True = 1` and `False = 0`.\n",
    "\n",
    "If we plot the average classified pixel value, pixels that are always water will have an average value of `1` and pixels that are always land will have an average of `0`.\n",
    "Pixels that are sometimes water and sometimes land will have an average between these values. In this case study, these pixels are associated with seasonally inundated wetland areas. \n",
    "\n",
    "The following cell plots the average classified pixel value, or the frequency of water detection, over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean of each classified pixel value\n",
    "plt.figure(figsize=(8, 7))\n",
    "S1.water.mean(dim='time').plot(cmap=\"RdBu\")\n",
    "plt.title(\"Average classified pixel value\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that the selected threshold has done a good job of separating the water pixels (in blue) and land pixels (in red) as well as ephemeral water features in between. \n",
    "\n",
    "You should be able to see that the shoreline takes on a mix of values between `0` and `1`, highlighting pixels that are sometimes land and sometimes water.\n",
    "This is likely to due to the effect of rising and falling tides, with some radar observations being captured at low tide, and others at high tide.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assessment with standard deviation\n",
    "\n",
    "Given that we've identified the shoreline as the pixels that are classified sometimes as land and sometimes as water, we can also see if the standard deviation of each pixel over time is a reasonable way to determine if a pixel is a shoreline or not.\n",
    "\n",
    "Similar to how we calculated and plotted the mean above, you can calculate and plot the standard deviation by using the `std` function in place of the `mean` function.\n",
    "\n",
    "If you'd like to see the results using a different colour scheme, you can also try substituting `cmap=\"Greys\"` or `cmap=\"Blues\"` in place of `cmap=\"viridis\"`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 7))\n",
    "S1.water.std(dim=\"time\").plot(cmap=\"viridis\")\n",
    "plt.title(\"Standard deviation of classified pixel values\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation we calculated above gives us an idea of how variable a pixel has been over the entire period of time that we looked at. From the image above, you should be able to see that the land and water pixels almost always have a standard deviation of `0`, meaning they didn't change over the time we sampled. The shoreline and wetlands however have a higher standard deviation, indicating that they change frequently between water and non-water.\n",
    "\n",
    "An important thing to recognise is that the standard deviation might not be able to detect the difference between noise, tides, and ongoing change, since a pixel that frequently alternates between land and water (noise) could have the same standard deviation as a pixel that is land for some time, then becomes water for the remaining time (ongoing change or tides)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "When you are done, return to the \"Analysis parameters\" section, modify some values (e.g. lat and lon) and rerun the analysis. You can use the interactive map in the \"View the selected location\" section to find new central latitude and longitude values by panning and zooming, and then clicking on the area you wish to extract location values for. You can also use Google maps to search for a location you know, then return the latitude and longitude values by clicking the map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Compatible datacube version:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last Tested:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "7073445e337f46189cb5f163631ca8d5": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     },
     "908a9dc9117c40a58c0270b0ac5c49f4": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
