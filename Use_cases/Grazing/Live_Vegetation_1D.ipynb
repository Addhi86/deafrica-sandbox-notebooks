{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Like Vegetation Trend Series in the Ruko Conservancy\n",
    "\n",
    "* **Products used:** \n",
    "[s2_l2a](https://explorer.digitalearth.africa/s2_l2a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Phenology is the study of plant and animal life cycles in the context of the seasons.\n",
    "It can be useful in understanding the life cycle trends of crops and how the growing seasons are affected by changes in climate.\n",
    "For more information, see the [USGS page on deriving phenology](https://www.usgs.gov/land-resources/eros/phenology/science/deriving-phenological-metrics-ndvi?qt-science_center_objects=0#qt-science_center_objects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "This notebook will produce annual, smoothed, **one-dimensional (zonal mean across a region)** time-series of a remote sensing vegetation indice, such as NDVI or EVI.  In addition, basic phenology statistics are calculated, exported to disk as csv files, and annotated on a plot.\n",
    "\n",
    "A number of steps are required to produce the desired outputs:\n",
    "\n",
    "1. Load satellite data for a region specified by an vector file (shapefile or geojson)\n",
    "2. Buffer the cloud masking layer to better mask clouds in the data (Sentinel-2 cloud mask is quite poor)\n",
    "3. Further prepare the data for analysis by removing bad values (infs), masking surafce water, and removing outliers in the vegetation index.\n",
    "4. Calculate a zonal mean across the study region (collapse the x and y dimension by taking the mean across all pixels for each time-step).\n",
    "5. Interpolate and smooth the time-series to ensure a consistent dataset with all gaps and noise removed.\n",
    "6. Calculate phenology statistics, report the results, save the results to disk, and generate an annotated plot.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Load key Python packages and supporting functions for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/env/lib/python3.8/site-packages/geopandas/_compat.py:106: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.9.1-CAPI-1.14.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n",
      "/env/lib/python3.8/site-packages/datacube/storage/masking.py:7: DeprecationWarning: datacube.storage.masking has moved to datacube.utils.masking\n",
      "  warnings.warn(\"datacube.storage.masking has moved to datacube.utils.masking\",\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import datacube\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import datetime as dt\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from datacube.utils import geometry\n",
    "import geopandas as gpd\n",
    "\n",
    "import sys\n",
    "\n",
    "from deafrica_tools.datahandling import load_ard\n",
    "from deafrica_tools.bandindices import calculate_indices\n",
    "from deafrica_tools.plotting import map_shapefile\n",
    "from deafrica_tools.dask import create_local_dask_cluster\n",
    "from deafrica_tools.spatial import xr_rasterize\n",
    "from deafrica_tools.plotting import map_shapefile\n",
    "from deafrica_tools import temporal as ts\n",
    "\n",
    "from deafrica_tools.classification import HiddenPrints\n",
    "\n",
    "from datacube.utils.aws import configure_s3_access\n",
    "configure_s3_access(aws_unsigned=True, cloud_defaults=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a Dask cluster\n",
    "\n",
    "Dask can be used to better manage memory use down and conduct the analysis in parallel. For an introduction to using Dask with Digital Earth Africa, see the Dask notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:40969</li>\n",
       "  <li><b>Dashboard: </b><a href='/user/nanaboamah/proxy/8787/status' target='_blank'>/user/nanaboamah/proxy/8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>31</li>\n",
       "  <li><b>Memory: </b>254.70 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:40969' processes=1 threads=31, memory=254.70 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_local_dask_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis parameters\n",
    "\n",
    "The following cell sets important parameters for the analysis:\n",
    "\n",
    "* `veg_proxy`: Band index to use as a proxy for vegetation health e.g. `'NDVI'` or `'EVI'`\n",
    "* `product`: The satellite product to load. Either Sentinel-2: `'s2_l2a'`, or Landsat-8: `'ls8_cl2'`\n",
    "* `shapefile`: The path to the vector file delineating the analysis region. Can be a shapefile or a geojson\n",
    "* `time_range`: The year range to analyse (e.g. `('2017-01-01', '2019-12-30')`).\n",
    "* `min_gooddata`: the fraction of good data (not cloudy) a scene must have before it is returned as a dataset \n",
    "* `resolution`: The pixel resolution, in metres, of the returned dataset\n",
    "* `dask_chunks`: The size, in number of pixel, for the dask chunks on each dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_proxy = 'MSAVI'\n",
    "\n",
    "product = 's2_l2a'\n",
    "\n",
    "shapefile='data/ccy.geojson'\n",
    "\n",
    "time_range = ('2018-01-01','2018-12-31')\n",
    "\n",
    "min_gooddata = 0.50\n",
    "\n",
    "resolution = (-50,50)\n",
    "\n",
    "dask_chunks = {'x':1500, 'y':1500}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "\n",
    "Connect to the datacube so we can access DE Africa data.\n",
    "The `app` parameter is a unique name for the analysis which is based on the notebook file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = datacube.Datacube(app='Live_Vegetation_phenology')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the region of interest\n",
    "The next cell will display the selected area on an web map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First open the shapefile using geopandas\n",
    "gdf = gpd.read_file(shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6896b4f65547b6a88216c271bb4405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d931a043aab4a739e0680f616495792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[1.158755580035329, 37.752218372858266], controls=(ZoomControl(options=['position', 'zoom_in_text',â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_shapefile(gdf, attribute='ConsrvName')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cloud-masked Sentinel-2 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to load Sentinel-2 data for the specified area of interest and time range. \n",
    "The `load_ard` function is used here to load data that has been masked for cloud, shadow and quality filters, making it ready for analysis.\n",
    "\n",
    "The cell directly below will create a query object using the first geometry in the shapefile, along with the parameters we defined in the Analysis Parameters section above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reusable query\n",
    "geom = geometry.Geometry(geom=gdf.iloc[0].geometry, crs=gdf.crs)\n",
    "\n",
    "query = {\n",
    "    \"geopolygon\": geom,\n",
    "    'time': (time_range),\n",
    "    'resolution': resolution,\n",
    "    'output_crs': 'epsg:6933',\n",
    "    'group_by':'solar_day'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load available data from S2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Tools/deafrica_tools/datahandling.py:260: UserWarning: Setting 'min_gooddata' percentage to > 0.0 will cause dask arrays to compute when loading pixel-quality data to calculate 'good pixel' percentage. This can slow the return of your dataset.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using pixel quality parameters for Sentinel 2\n",
      "Finding datasets\n",
      "    s2_l2a\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 60 out of 71 time steps with at least 50.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Returning 60 time steps as a dask array\n",
      "<xarray.Dataset>\n",
      "Dimensions:      (time: 60, x: 3455, y: 4592)\n",
      "Coordinates:\n",
      "  * time         (time) datetime64[ns] 2018-01-04T07:54:25 ... 2018-12-30T07:...\n",
      "  * y            (y) float64 2.626e+05 2.625e+05 ... 3.308e+04 3.302e+04\n",
      "  * x            (x) float64 3.556e+06 3.556e+06 ... 3.729e+06 3.729e+06\n",
      "    spatial_ref  int32 6933\n",
      "Data variables:\n",
      "    red          (time, y, x) float32 dask.array<chunksize=(1, 1500, 1500), meta=np.ndarray>\n",
      "    blue         (time, y, x) float32 dask.array<chunksize=(1, 1500, 1500), meta=np.ndarray>\n",
      "    nir          (time, y, x) float32 dask.array<chunksize=(1, 1500, 1500), meta=np.ndarray>\n",
      "    green        (time, y, x) float32 dask.array<chunksize=(1, 1500, 1500), meta=np.ndarray>\n",
      "    swir_1       (time, y, x) float32 dask.array<chunksize=(1, 1500, 1500), meta=np.ndarray>\n",
      "    SCL          (time, y, x) uint8 dask.array<chunksize=(1, 1500, 1500), meta=np.ndarray>\n",
      "Attributes:\n",
      "    crs:           epsg:6933\n",
      "    grid_mapping:  spatial_ref\n"
     ]
    }
   ],
   "source": [
    "ds = load_ard(\n",
    "    dc=dc,\n",
    "    products=['s2_l2a'],\n",
    "    dask_chunks=dask_chunks,\n",
    "    min_gooddata=min_gooddata,\n",
    "    measurements =['red','blue','nir','green','swir_1','SCL'],\n",
    "    **query,\n",
    ")\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Buffering\n",
    "\n",
    "The cloud masking data for Sentinel-2 is less than perfect, and missed cloud in the data greatly impacts vegetation  calculations. Below we will buffer the cloud-masking bands in an attempt to improve the masking of poor quality data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import odc.algo\n",
    "\n",
    "#Extract boolean mask\n",
    "mask = odc.algo.enum_to_bool(ds.SCL, \n",
    "                             categories=['cloud shadows', 'cloud medium probability',\n",
    "                                         'cloud high probability', 'thin cirrus'])\n",
    "                             \n",
    "# Close mask to remove small holes in cloud, open mask to \n",
    "# remove narrow false positive cloud, then dilate\n",
    "mask = odc.algo.binary_closing(mask, 2)\n",
    "#mask_cleaned = odc.algo.mask_cleanup(mask, r=(2, 10))\n",
    "\n",
    "# Add new mask as nodata pixels\n",
    "ds = odc.algo.erase_bad(ds, mask)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask the satellite data with shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mask\n",
    "mask = xr_rasterize(gdf,ds)\n",
    "\n",
    "#mask data\n",
    "ds = ds.where(mask)\n",
    "\n",
    "#remove SCL since we don't need it anymore\n",
    "ds = ds.drop('SCL')\n",
    "\n",
    "#convert to float 32 to conserve memory\n",
    "ds=ds.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate vegetation and water indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multiply red and nir band by 100\n",
    "ds['red'] = ds['red']  * 100\n",
    "ds['nir'] = ds['nir'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def field_MSAVI2(ds):\n",
    "    return (ds + 0.0018) / 0.877 \n",
    "\n",
    "def live_veg_frac_cover(ds):\n",
    "    ds_live = (103.89 * ds) * 2.55\n",
    "    return ds_live.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the chosen vegetation proxy index and add it to the loaded data set\n",
    "ds = calculate_indices(ds, index=[veg_proxy, 'MNDWI'], collection='s2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['field_MSAVI2'] = field_MSAVI2(ds['MSAVI'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['live_veg_frac_cover'] = live_veg_frac_cover(ds['field_MSAVI2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop bands that are no longer needed (save memory)\n",
    "ds = ds.drop(['red','green','nir','blue','swir_1', 'field_MSAVI2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for analysis\n",
    "\n",
    "Remove any NaN or infinite values, mask water, remove any outliers in the vegetation index.  We then reduce the data to a 1D timeseries by calculating the mean across the x and y dimensions.  \n",
    "\n",
    "We will also 'compute' the data on the dask cluster to speed up calculations later on. This step will take 5-10mins to run since we are now computing everything that came before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_proxy = 'live_veg_frac_cover'\n",
    "# remove any infinite values\n",
    "ds = ds.where(xr.ufuncs.isfinite(ds))\n",
    "\n",
    "# mask water\n",
    "ds = ds.where(ds.MNDWI < 0)\n",
    "\n",
    "ds[veg_proxy] =  ds[veg_proxy] / 2.55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[veg_proxy] = ds[veg_proxy].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[veg_proxy] = xr.where(ds[veg_proxy] < 0, np.nan, ds[veg_proxy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 1D line plots\n",
    "veg = ds[veg_proxy].mean(['x', 'y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smooth and interpolate time series\n",
    "\n",
    "Due to many factors (e.g. cloud obscuring the region, missed cloud cover in the SCL layer) the data will be gappy and noisy. Here, we will smooth and interpolate the data to ensure we working with a consistent time-series.\n",
    "\n",
    "To do this we take two steps:\n",
    "\n",
    "1. Resample the data to fortnightly time-steps using the fortnightly median\n",
    "2. Calculate a rolling mean with a window of 4 steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resample_period='4W'\n",
    "window=4\n",
    "\n",
    "veg_smooth=veg.resample(time=resample_period, label='left', loffset='1W').median().rolling(time=window, min_periods=1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the entire time-series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veg_smooth.plot.line('b-^', figsize=(15,5))\n",
    "\n",
    "\n",
    "plt.title(veg_proxy+' time-series');\n",
    "plt.savefig(f'results/yearly_fractional_cover_{time_range}_plot.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_ds = dc.load(product='rainfall_chirps_monthly', **query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, ax1 = plt.subplots(figsize=(15,8))\n",
    "\n",
    "# plt.subplot(2,1,1)\n",
    "rf_ds['rainfall'].sum(['x','y']).plot(marker='^', markersize=4, linewidth=1, ax=ax1, linestyle='dashed', \n",
    "                                    label=' Rainfall');\n",
    "\n",
    "plt.ylabel('%s (%s)'%('Total Precipitation', rf_ds['rainfall'].attrs['units']));\n",
    "plt.title('')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "veg_smooth.plot(color='green', marker='^', markersize=4, linewidth=1, ax=ax2, \n",
    "                         label='Live Vegetation Cover')\n",
    "plt.title('')\n",
    "plt.ylabel('Live Vegatation Cover(%)', color='green')\n",
    "plt.yticks(color='green')\n",
    "\n",
    "fig.legend(loc='upper left', bbox_to_anchor=(0.05, 0.93))\n",
    "fig.suptitle(f'Live Vegetation Cover compared to rainfall (CHIRPS) over time from {time_range[0]} to {time_range[1]}')\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(f'results/yearly_fractional_cover_rainfall_{time_range}_plot.png');\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Africa data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/digitalearthafrica/deafrica-sandbox-notebooks).\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Last Tested:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "datetime.today().strftime('%Y-%m-%d')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1d2ba241bfd2437dbdf5d4530c685d9a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     },
     "d867097fe154472198694ed8095e3b0c": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
